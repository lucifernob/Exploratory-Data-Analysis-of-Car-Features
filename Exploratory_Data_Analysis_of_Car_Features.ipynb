{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exploratory Data Analysis of Car Features.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "cLYy6-OZaxjA",
        "txOHBj0enPui",
        "DX1l2uVysU_Z",
        "N7gAUtMDwuDe",
        "Uvz31baGA1a2",
        "C5qMTUprWnoh",
        "uRU42vmga-26",
        "uKC0lEmbFE8i",
        "-eOQrWVu2byn",
        "mYmYeeKC2mKV",
        "Wt6UZ9GajDd1",
        "I5FAHdD8jFcD"
      ],
      "authorship_tag": "ABX9TyPT6QeQ3ej8NBxB2o6q5vWS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lucifernob/Exploratory-Data-Analysis-of-Car-Features/blob/master/Exploratory_Data_Analysis_of_Car_Features.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Th40AMQHUG7z",
        "colab_type": "text"
      },
      "source": [
        "###**Exploratory Data Analysis of Car Features**\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BUNLAzgEJzb",
        "colab_type": "text"
      },
      "source": [
        "#Table of Contents\n",
        "\n",
        "[Problem statement](#scrollTo=cLYy6-OZaxjA)\n",
        "\n",
        "1. [Importing libraries](#scrollTo=txOHBj0enPui)\n",
        "      *   Loading the data file\n",
        "      *   Loading the data into the datafiles\n",
        "      *   Checking the types of data and basic summary stats\n",
        "2. [Dropping irrelevant data](#scrollTo=DX1l2uVysU_Z)\n",
        "3. [Renamming the columns](#scrollTo=N7gAUtMDwuDe)\n",
        "4. [Removing duplicate data](#scrollTo=Uvz31baGA1a2)\n",
        "      *   Dropping duplicate rows\n",
        "      *   Dropping null/missing values\n",
        "5. [Detecting outliers](#scrollTo=C5qMTUprWnoh)\n",
        "6. [Top car brands and average price](#scrollTo=uRU42vmga-26)\n",
        "      *   Top 10 car brands\n",
        "      *   Average price of car\n",
        "      *   Top 5 highest selling car\n",
        "      *   Top 5 least popular cars\n",
        "7. [Correlation matrix](#scrollTo=uKC0lEmbFE8i)\n",
        "8. [Plotting different graphs & Performing EDA](#scrollTo=-eOQrWVu2byn)\n",
        "      *   Scatter plots\n",
        "      *   Heat Map\n",
        "      *   Most sold car segment\n",
        "      *   Forming new group \"price_group\"\n",
        "      *   Multivariate Graphs\n",
        "      *   Pair Plot\n",
        "9. [Basic Machine learning model](#scrollTo=mYmYeeKC2mKV)\n",
        "      *   Splitting the dataset\n",
        "      *   ML with linear regression\n",
        "10. [Spot checking algorithms](#scrollTo=g03tzB_J7j8s)\n",
        "      *   Polynomial regression\n",
        "      *   SVR regression\n",
        "      *   Random Forest\n",
        "\n",
        "[Downloading the output graphs we made](#scrollTo=Wt6UZ9GajDd1)\n",
        "\n",
        "[Conclusion](#scrollTo=I5FAHdD8jFcD)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLYy6-OZaxjA",
        "colab_type": "text"
      },
      "source": [
        "##**Problem Statement**\n",
        "To perform Exploratory data analysis(EDA) on how the different features of a car and its price are related. \n",
        "\n",
        "TheÂ below code explore the basic use of Pandas and will cover the basic commands & features of (EDA) i.e. cleaning, combining, reshaping, transforming data for analysis purpose..\n",
        "\n",
        "EDA is a critical and building block in analyzing the data and we do this for various purpose like for \n",
        "\n",
        "*   finding patterns in Data\n",
        "*   Determining relationships in Data\n",
        "*   Detection of mistakes and many more.\n",
        "\n",
        "The data comes from the [Kaggle dataset](https://www.kaggle.com/CooperUnion/cardataset) \"Car Features and MSRP\". It describes almost 12,000 car models, sold in the USA between 1990 and 2017, with the market price (new or used) and some features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txOHBj0enPui",
        "colab_type": "text"
      },
      "source": [
        "# **1. Importing libraries**\n",
        "\n",
        "Importing all the libraries which we will be required for the project."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBRgLJ1mnHTL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd                                                             # For data manipulation and analysis\n",
        "import numpy as np                                                              # Implemennts milti-dimensional array and matrices\n",
        "import seaborn as sns                                                           # Used for high level Data Visualisation\n",
        "import matplotlib.pyplot as plt                                                 # Plotting library for Python programming language and it's numerical\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfsDiCnSISMJ",
        "colab_type": "text"
      },
      "source": [
        "**1.1 Load data file**\n",
        "\n",
        "The data file is in .csv format and for importing there are 3 main methods: \n",
        "- From local drive (For ease we will use it)\n",
        "- From URL\n",
        "- From google drive\n",
        "\n",
        "\n",
        "> *Note: Using \"import from local drive\" may require you to load data file every time you run the code, so import from google drive is better option.*\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFwwELeeDgJT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Import data file from your google drive\n",
        "'''\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")\n",
        "\n",
        "import pandas as pd\n",
        "pd.read_csv('/content/gdrive/My Drive/Internship studio/Project/data.csv')      # Copy your file path and replace with the given path\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEraWMR6n6Zb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Import data file for local drive\n",
        "from google.colab import files           \n",
        "uploaded=files.upload()                                                         #it will create upload option to load your desired file form your local drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTQsaCu8oZSq",
        "colab_type": "text"
      },
      "source": [
        "**1.2 Loading the data into the datafiles**\n",
        "\n",
        "The data comes from the Kaggle dataset \"Car Features and MSRP\". It describes almost 12,000 car models, sold in the USA between 1990 and 2017, with the market price (new or used) and some features.\n",
        "\n",
        "Load the required data file for data analysis, and check whether data is loaded properly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSyGIrFQoc9q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import io\n",
        "df = pd.read_csv(io.BytesIO(uploaded['data.csv']))                              #Reading the file \"data.cv\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "paaM6YsMoqeS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#To display the top 10 rows\n",
        "df.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7FWyYibp0yh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#To display the bottom 10 rows\n",
        "df.tail(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcymOJvTp6Wp",
        "colab_type": "text"
      },
      "source": [
        "**1.3 Checking the types of data and basic summary stats**\n",
        "\n",
        "Sometimes the data is not in correct format, like integer data is stored as string so we need to convert it, hence we check data type here.\n",
        "\n",
        "\n",
        "> Note: Don't procede furthere before checking data type.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhhVOKoeqERi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.info()                                                                       # This will give Index, Datatype and Memory information"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ss9Y_EZ_qzC6",
        "colab_type": "text"
      },
      "source": [
        "There was no data which require change in its format so we will procede futher, if you find any do change its data type and then move ahead."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HyYNh1vbsGiM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.describe(include = \"all\")                                                    # Use include='all' option to generate descriptive statistics for all columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQrtk_NTsZ9y",
        "colab_type": "text"
      },
      "source": [
        "From describe we can get the basiz idea that \"Engine HP\" and \"Engine cylinders\" don't have value 11914 like other prameters so it means they have some missing data, don't worry We will change and see them in coming section."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DX1l2uVysU_Z",
        "colab_type": "text"
      },
      "source": [
        "# **2. Dropping irrelevant data**\n",
        "\n",
        "When we import data, there are chances of irrlevant data i.e. data which is not much necessary for anaylsiying, so we will remove that column or row which is less relvant for us.\n",
        "\n",
        "\n",
        "> Dropping of irrelvant data can have multiple rows of same data, some missing values, so as per our need we can remove them or imput the new values, remember: More data we provide, More accurate result we will get. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jckpw-cTs276",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df=df.drop(['Number of Doors','Market Category'], axis=1)                       #axis is basically row, here from row ! drop the labelled column.\n",
        "df.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3y5mOJyrfQD",
        "colab_type": "text"
      },
      "source": [
        "In this case parameters such as \"No. of doors\", \"Market categorry\" are not making such big impact in our analysing so we drop those parameter."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7gAUtMDwuDe",
        "colab_type": "text"
      },
      "source": [
        "#**3. Renaming the columns**\n",
        "Our data have some big terms so for our ease we will rename some parameters for the better understanding of data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QnaHZNI_tW3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df=df.rename(columns={\"Engine HP\": \"HP\", \"Engine Cylinders\": \"Cylinders\", \"Transmission Type\": \"Transmission\", \"Driven_Wheels\": \"Drive Mode\",\"highway MPG\": \"MPG-H\", \"city mpg\": \"MPG-C\", \"MSRP\": \"Price\"})\n",
        "df.head(10)                                                                     #Seeing top 10 data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uvz31baGA1a2",
        "colab_type": "text"
      },
      "source": [
        "#**4. Dropping duplicate data**\n",
        "\n",
        "There is a chance of duplicate data or null values in large dataset so either we should remove them or impute new values here..\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4TfOzu8BKF0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.shape                                                                        # size of data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKw7hdF9dSSv",
        "colab_type": "text"
      },
      "source": [
        "**4.1 Dropping duplicate rows**\n",
        "\n",
        "We will drop the rows which have duplicate data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XOEoIvuBXaz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "duplicate_rows_df=df[df.duplicated()]                                           #Finding duplicate rows\n",
        "print(\"No. of duplicate rows= \", duplicate_rows_df.shape)                       #Print how many rows with duplicate data are present."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laQDWY6aDH4A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df=df.drop_duplicates()                                                         #Drop duplicate data\n",
        "df.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUMVQoWVDbvm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.shape                                                                        #So we are left with less rows after removing suplicate rows."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIs6BmV5Dtmz",
        "colab_type": "text"
      },
      "source": [
        "**4.2 Dropping the missing or null values**\n",
        "\n",
        "Similar to previous there is a chance of null values in large dataset so removing them is better idea, the data set contain very few null values so we can remove them instead of adding.\n",
        "\n",
        "> *NOTE: Instead of removing the the null values we can also impute the values which are missing, this approach is better than dropping as the more data we provide to the system more accurate result we will get.*\n",
        "> If we need to impute values we will prefer imputing with the median values of that column and not mean it is more robust to outlier.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtknnUhJEEqj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Printing the data with null vaues.\n",
        "print (df.isnull().sum())                                                       # Will show you null count for each column, but remember it will not count Zeros(0) as null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPR0IpnES8fp",
        "colab_type": "text"
      },
      "source": [
        "As we can see \"Market category\" has max. missing values followed by \"Engine HP\" & \"Engine Cylinders\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXw75FMkFy6U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Dropping the null values\n",
        "df=df.dropna()\n",
        "df.count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIk6P3FFGZ9e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Rechecking how many null values are there now after removing\n",
        "print(df.isnull().sum())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5qMTUprWnoh",
        "colab_type": "text"
      },
      "source": [
        "#**5. Detecting outliers**\n",
        "\n",
        "We will use boxplot to plot the outkiers and then remove them.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkAerGfhXCEc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.set_style(\"whitegrid\")\n",
        "sns.boxplot(x=df['Year'],color=\"#AEB404\");\n",
        "\n",
        "# saving the plot\n",
        "plt.savefig(\"Detecting outliers-1.pdf\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vacfFORNYE1K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.set_style(\"whitegrid\")\n",
        "sns.boxplot(x=df['HP'],color=\"#74DF00\");\n",
        "\n",
        "# saving the plot\n",
        "plt.savefig('Detecting outliers-2.pdf')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBrY_F_PYHLd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.set_style(\"whitegrid\")\n",
        "sns.boxplot(x=df['Cylinders']);\n",
        "\n",
        "# saving the plot\n",
        "plt.savefig('Detecting outliers-3.pdf')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J19Bll8YYLUz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.set_style(\"whitegrid\")\n",
        "sns.boxplot(x=df['MPG-H'],color=\"#424242\");\n",
        "\n",
        "# saving the plot\n",
        "plt.savefig('Detecting outliers-4.pdf')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7U_PSgJCY945",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.set_style(\"whitegrid\")\n",
        "sns.boxplot(x=df['MPG-C'],color=\"#8000FF\");\n",
        "\n",
        "# saving the plot\n",
        "plt.savefig('Detecting outliers-5.pdf')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mguwa7njZDWU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.set_style(\"whitegrid\")\n",
        "sns.boxplot(x=df['Popularity'],color=\"#0489B1\");\n",
        "\n",
        "# saving the plot\n",
        "plt.savefig('Detecting outliers-6.pdf')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdFLymNiZKP7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.set_style(\"whitegrid\")\n",
        "sns.boxplot(x=df['Price'],color=\"#088A68\");\n",
        "\n",
        "# saving the plot\n",
        "plt.savefig('Detecting outliers-7.pdf')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUKvZYOQZf72",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Q1=df.quantile(0.25)                                                            #Whisker 1\n",
        "Q3=df.quantile(0.75)                                                            #whisker 2\n",
        "IQR=Q3-Q1                                                                       #interquartile range here\n",
        "print(IQR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOrEfl3sZ009",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df=df[~((df<(Q1-1.5*IQR))| (df>(Q3+1.5*IQR))).any(axis=1)]                      #Standard formula but we can also use mean to \n",
        "df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSjgn94aXKzY",
        "colab_type": "text"
      },
      "source": [
        "After removing and editing all the irrelevant data from data size (11193, 14) we came to data size of (8608, 14)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRU42vmga-26",
        "colab_type": "text"
      },
      "source": [
        "#**6. Most represented car brands**\n",
        "\n",
        "In this section we will find top 10 car brands and calculate there average price of the car brand wise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7hL659DdPF5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Percentage of car brand\n",
        "counts=df['Make'].value_counts()*100/sum(df['Make'].value_counts())\n",
        "\n",
        "#Top 10car brands\n",
        "popular_labels=counts.index[:10]\n",
        "\n",
        "#Plot\n",
        "plt.figure(figsize=(14,6))\n",
        "plt.barh(popular_labels,width=counts[:10],color=\"#086A87\")\n",
        "plt.title('Top 10 car brands', fontsize=\"15\")\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIWdJbQUXxfT",
        "colab_type": "text"
      },
      "source": [
        "We got are top 10 car brands and as we can see **Chevrolet** is the winner among among all the car brands, hence it is preferred by majority of people."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEZxuckcegME",
        "colab_type": "text"
      },
      "source": [
        "**6.1 Average price among the top car brands**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpWvIsqXAjS-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prices=df[['Make','Price']].loc[\n",
        "                                (df['Make']=='Chevrolet') |\n",
        "                                (df['Make']=='Toyota') |\n",
        "                                (df['Make']=='Volkswagen') |\n",
        "                                (df['Make']=='Nissan') |\n",
        "                                (df['Make']=='GMC') |\n",
        "                                (df['Make']=='Dodge') |\n",
        "                                (df['Make']=='Mazda') | \n",
        "                                (df['Make']=='Honda') |\n",
        "                                (df['Make']=='Suzuki') |\n",
        "                                (df['Make']=='Infiniti')].groupby('Make').mean()\n",
        "print(round(prices,2));                                                         #Printing average price upto 2 values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQi1tgx4gwUY",
        "colab_type": "text"
      },
      "source": [
        "**6.2 Top 5 highest selling car**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evL_OsEtc245",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df[df.Price.isin(df.Price.nlargest(5))].sort_values(['Model','Make','MPG-H','MPG-C','Popularity','Price'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQ6p5Y5ve_bZ",
        "colab_type": "text"
      },
      "source": [
        "This shows top 5 **highest price** selling car and their models details preffered by high profile income group peoples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDArlL_MhC4B",
        "colab_type": "text"
      },
      "source": [
        "**6.3 Top 5 least popular cars**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWLItI4Bd9Ns",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df[df.Popularity.isin(df.Popularity.nsmallest(5))].sort_values(['Model','Make','MPG-H','MPG-C',\"Popularity\",'Price'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYqvCRjCgZRW",
        "colab_type": "text"
      },
      "source": [
        "This shows top 5 **lowest popular** selling car and their models details and hence these models can avoided for selling."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKC0lEmbFE8i",
        "colab_type": "text"
      },
      "source": [
        "#**7. Correlation matrix** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXzUyRPBFBEC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Performing correlation\n",
        "df.corr()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLdaxc0NJ252",
        "colab_type": "text"
      },
      "source": [
        "**Correlation & Anticorrelation**\n",
        "\n",
        "From the above anlysis we obseve there is \n",
        "\n",
        "\n",
        "1.   High correlation between \n",
        "\n",
        "      *   Cylinders and HP\n",
        "      *   Highway mpg and City mpg\n",
        "      *   HP and Price\n",
        "\n",
        "\n",
        "\n",
        "More the the cylinders present in car more will the horse power i.e. more power.\n",
        "\n",
        "2.   Hight Anticorrelation between\n",
        "\n",
        "      *   Cylinders and highway mpg\n",
        "\n",
        "More the cylinders present more is the power which results in more fuel consumption hence less mileage.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-eOQrWVu2byn",
        "colab_type": "text"
      },
      "source": [
        "#**8. Plotting different graphs & Performing EDA**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VkJokcXNm6s",
        "colab_type": "text"
      },
      "source": [
        "**8.1 Scatterplots**\n",
        "\n",
        "Scatter plot is used to find the correlation between two variables. As from the previous result we see strong correlation between **Cylinders and HP**, **Highway mpg and City mpg** and **HP and Price** and also  too, so we plot the graph for them and then draw the trend line."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLuYQzTfNA3H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Scatterplot between HP & Cylinders\n",
        "\n",
        "fig, ax=plt.subplots(figsize=(10,6))\n",
        "ax.scatter(df['Cylinders'], df['HP'], color='#2E64FE')\n",
        "sns.set()                                                                       #set background 'dark grid'\n",
        "plt.title(\"Scatter Plot of Cylinders and HP\", fontsize = 25)\n",
        "ax.set_xlabel('Cylinders',fontsize= 15)\n",
        "ax.set_ylabel('HP',fontsize= 15)\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "auJQDba9jE4Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Scatterplot between HP & Cylinders\n",
        "\n",
        "fig, ax=plt.subplots(figsize=(10,6))\n",
        "ax.scatter(df['MPG-H'], df['MPG-C'], color='#800000')\n",
        "plt.title(\"Scatter Plot between MPG-C MPG-H\", fontsize = 25)\n",
        "ax.set_xlabel('MPG-H',fontsize= 15)\n",
        "ax.set_ylabel('MPG-C',fontsize= 15)\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZfresxHOzNP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Scatterplot between HP & Price\n",
        "\n",
        "fig, ax=plt.subplots(figsize=(10,6))\n",
        "ax.scatter(df['HP'], df['Price'],color='#04B431')\n",
        "plt.title(\"Scatter Plot between Price and HP\", fontsize = 25)\n",
        "ax.set_xlabel('HP',fontsize= 15)\n",
        "ax.set_ylabel('Price',fontsize= 15)\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yr73uZIMhHT",
        "colab_type": "text"
      },
      "source": [
        "**8.2 Heat Map**\n",
        "\n",
        "Heat Map is also preffered to find the correlation between two variables. Below graph shows the which features are most relative and dependent on each other. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeYNBlGmMMYd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(12,8))\n",
        "c=df.corr()\n",
        "sns.heatmap(c,cmap=\"BrBG\", annot=True, linewidths=0.5);\n",
        "\n",
        "# saving the plot\n",
        "plt.savefig('Heat Map.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRxxyE2-maCu",
        "colab_type": "text"
      },
      "source": [
        "Hence it looks Cylinders and HP, Highway mpg and City mpg, HP and Price are more dependnt on each other the we see Hight Anticorrelation between Cylinders and highway mpg. Just same as correlation matrix we studied before."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cw91qe7XPaFf",
        "colab_type": "text"
      },
      "source": [
        "**8.3 Most sold car segment**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9-u1GcZO88M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Bar chart for car \"Body\" variable\n",
        "df[\"Vehicle Style\"].value_counts().plot.bar(figsize=(10,6),color=\"#FF8000\")\n",
        "sns.set()  \n",
        "plt.title(\"Most car sold\",fontsize= 15)\n",
        "plt.xlabel(\"Car type\",fontsize= 15)\n",
        "plt.ylabel(\"No. of vehicles\",fontsize= 15);\n",
        "\n",
        "# saving the plot\n",
        "plt.savefig('Most car sold.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMh5m3CiQoCn",
        "colab_type": "text"
      },
      "source": [
        "From the chart we can see **Sedan** cars were the most sold cards followed by 4dr SUV."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEWPTFzbQyLM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Vehicle style type and Drive type analysis\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.figure(figsize=(25,15))\n",
        "sns.countplot(y=\"Vehicle Style\", data=df, hue=\"Drive Mode\")\n",
        "plt.title(\"Vehicle Type v/s Drive mode Type\", fontsize=\"20\")\n",
        "plt.ylabel(\"Vehicle Type\",fontsize= 15)\n",
        "plt.xlabel(\"Count of vehicles\",fontsize= 15)\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ji-JgBannWV6",
        "colab_type": "text"
      },
      "source": [
        "For the deeper understanding we found that **front wheel drive in sedan type** followed by **all wheel drive in 4dr SUV** are mostly preferred by people."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMw150hPVBxR",
        "colab_type": "text"
      },
      "source": [
        "**8.4 Forming new group \"price_group\"**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I32e8uLIVLXg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create a new group \"price_group\" and assign the value based on the car price\n",
        "\n",
        "df[\"price_group\"]=pd.cut(df[\"Price\"],[0,10000,20000,40000,60000,80000,100000,500000],\n",
        "                          labels=[\"<10k\",\"10-19K\",\"20-39K\",\"40-59K\",\"60-79K\",\"80-99K\",\">100k\"], include_lowest=True)\n",
        "df[\"price_group\"]=df[\"price_group\"].astype(object)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdr_S7dXVHMb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(df[\"price_group\"].value_counts()/len(df)*100).plot.bar(figsize=(10,6),color=('grey', 'red', 'green', 'blue', 'black'))\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.title(\"Price Group bar diagram\")\n",
        "plt.ylabel(\"% of vehicles\",fontsize= 15)\n",
        "plt.xlabel(\"Price Group\",fontsize= 15);\n",
        "\n",
        "# saving the plot\n",
        "plt.savefig('Price group.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2gUg233qFKn",
        "colab_type": "text"
      },
      "source": [
        "Hence, we divided price among 5 groups and we can see **more than 50% of cars are sold between price range of \"20-39k US dollars.\"** and least sold are for the price range 60-79k."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRTmROn_y17G",
        "colab_type": "text"
      },
      "source": [
        "**8.5 Multivariate Graphs**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXqd0lxdrKQI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.lmplot('Year','Price', df, fit_reg=False, hue='Vehicle Size', height=8,aspect=1.5)\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.title(\"Price distribution over the years w.r.t Vehicle size\", fontsize=\"25\")\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q56jc-bXyzrH",
        "colab_type": "text"
      },
      "source": [
        "The above multivariate graphs shows the Price distribution over the years w.r.t Vehicle size. As the years increase, people bought high price range car or it might means as the year increase rate of cars also increased, but the important aspect which needs to be notices is that, in any time frame **people prefer buying \"Large\" vehicle size cars**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Va3-mvZs6paX",
        "colab_type": "text"
      },
      "source": [
        "**8.6  Pair Plot**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBgnOCC43OJs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.set_color_codes()\n",
        "sns.set()  \n",
        "sns.pairplot(df, hue='Vehicle Size', height=2, aspect=1.5)\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34MaBuhJ3N0H",
        "colab_type": "text"
      },
      "source": [
        "This pairplot gives the observations which already have been referred from other graphs above, such as:\n",
        "\n",
        "*     Most prefered car size over the years is \"Large\"\n",
        "*     Large car give 0-30MPG-C, MPG-H and midsize gives above 30 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYmYeeKC2mKV",
        "colab_type": "text"
      },
      "source": [
        "#**9. Basic Machine learning model**\n",
        "\n",
        "With \"Price\" as the target variable we will build a machine learning model.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WT_AXhqOZQmN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x=df[[\"Year\",\"HP\",\"Cylinders\",\"MPG-H\",\"MPG-H\",\"Popularity\"]]\n",
        "y=df[\"Price\"].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gJc5OMA3V02",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Feature scaling, it will help in faster optimizing\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc_x=StandardScaler()\n",
        "sc_y=StandardScaler()\n",
        "x=sc_x.fit_transform(x)\n",
        "y=sc_y.fit_transform(y.reshape(-1,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1AdLfgqKgyYu",
        "colab_type": "text"
      },
      "source": [
        "**9.1 Splitting the data set**\n",
        "\n",
        "We split the data set into 80-20."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsSsfIMm37Ch",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Splitting the dataset into the Training set and Test set\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test=train_test_split(x,y,test_size=0.2,random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wM-74T5kg5Er",
        "colab_type": "text"
      },
      "source": [
        "**9.2 ML with linear regression**\n",
        "\n",
        "Performing Linear Regression with \"Price\" as the target variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2eeUGAB4kN-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Fitting Multiple Linear regression to the training set\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "regressor=LinearRegression()\n",
        "regressor.fit(x_train,y_train);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mYlRk8s4i8o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#predicting the test set results\n",
        "\n",
        "sns.set()\n",
        "plt.figure(figsize=(10,6))\n",
        "y_pred=regressor.predict(x_test)\n",
        "plt.scatter(y_test,y_pred,color=\"#610B21\");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0ZcJaAM6Qtw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.set()\n",
        "sns.distplot((y_test-y_pred),bins=50,color=\"#610B21\");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEpLwrKh6xlG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import metrics\n",
        "print(\"Mean Absolute error=\", metrics.mean_absolute_error(y_test,y_pred))\n",
        "print(\"Root Mean Squared Error=\", np.sqrt(metrics.mean_squared_error(y_test,y_pred)))\n",
        "print(\"R2 Score=\", metrics.r2_score(y_test,y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hBMc7MV9sgG",
        "colab_type": "text"
      },
      "source": [
        "From the metrics, we can see \"Linear regression\" is not having good performance, like root square value is just \"0.654\", which is very poor, so will try different algorithms to get better performance from our model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g03tzB_J7j8s",
        "colab_type": "text"
      },
      "source": [
        "#**10. Spot checking algorithms**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rjfn6yBih-T_",
        "colab_type": "text"
      },
      "source": [
        "**10.1 Polynomial Regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41XXaRxX7iuf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Fitting Polynomial Regression to the data set\n",
        "\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "poly_reg=PolynomialFeatures(degree=4)\n",
        "x_poly=poly_reg.fit_transform(x_train)\n",
        "poly_reg.fit(x_poly,y_train)\n",
        "lin_reg2=LinearRegression()\n",
        "lin_reg2.fit(x_poly,y_train);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fl1ly5Gv8a74",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Prediciting th new result with Polynnomial Regression\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "y_pred=lin_reg2.predict(poly_reg.fit_transform(x_test))\n",
        "plt.scatter(y_test,y_pred,color=\"#AEB404\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVFkI8vk890I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.distplot((y_test-y_pred),bins=50,color=\"#AEB404\");                          #Plotting the graph"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7VLoHja9lv0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Checking the performance over metrics\n",
        "\n",
        "from sklearn import metrics\n",
        "print(\"Mean Absolute error=\", metrics.mean_absolute_error(y_test,y_pred))\n",
        "print(\"Root Mean Squared Error=\", np.sqrt(metrics.mean_squared_error(y_test,y_pred)))\n",
        "print(\"R2 Score=\", metrics.r2_score(y_test,y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6IfNMG-_e1F",
        "colab_type": "text"
      },
      "source": [
        "Here we can see Polynomial Regression is way better than \"Linear Regression\" we got more accurate result, with R2 valued \"0.79\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suLCgdohiHFE",
        "colab_type": "text"
      },
      "source": [
        "**10.2 SVR regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9Zn8KFD-DFa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Fitting SVR to the dataset\n",
        "\n",
        "from sklearn.svm import SVR\n",
        "regressor=SVR(kernel=\"rbf\")\n",
        "regressor.fit(x_train,y_train);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKpZHz25-lQh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Predicting the new result\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "y_pred=regressor.predict(x_test)\n",
        "plt.scatter(y_test,y_pred);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ununR_3M-0GC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.distplot((y_test-y_pred),bins=50);                                          #Plotting the grapph"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nPPJZTD-6ho",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Checking the performance over metrics\n",
        "\n",
        "from sklearn import metrics\n",
        "print(\"Mean Absolute error=\", metrics.mean_absolute_error(y_test,y_pred))\n",
        "print(\"Root Mean Squared Error=\", np.sqrt(metrics.mean_squared_error(y_test,y_pred)))\n",
        "print(\"R2 Score=\", metrics.r2_score(y_test,y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWm8Xj1o_C0C",
        "colab_type": "text"
      },
      "source": [
        "Here in SVR Regression we got more accurate result, with R2 valued \"0.80\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQnkQuZ3iawg",
        "colab_type": "text"
      },
      "source": [
        "**10.3 Random Forest**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtjgFY33_Jd4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Fitting Random Forest Regression to the dataset\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "regressor=RandomForestRegressor(n_estimators=300,random_state=0)\n",
        "regressor.fit(x_train,y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJz3Hpo8_xO2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Predicting the new result\n",
        "\n",
        "plt.figure(figsize=(10,6),)\n",
        "y_pred=regressor.predict(x_test)\n",
        "plt.scatter(y_test,y_pred,color=\"#33cc33\");\n",
        "\n",
        "# saving the plot\n",
        "plt.savefig('Random forest.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfvoHvmoADc7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.distplot((y_test-y_pred),bins=50,color=\"#33cc33\");                          #Plotting the grapph\n",
        "\n",
        "# saving the plot\n",
        "plt.savefig('Random forest-1.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEAFqDgHAFhL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Checking the performance over metrics\n",
        "\n",
        "from sklearn import metrics\n",
        "print(\"Mean Absolute error=\", metrics.mean_absolute_error(y_test,y_pred))\n",
        "print(\"Root Mean Squared Error=\", np.sqrt(metrics.mean_squared_error(y_test,y_pred)))\n",
        "print(\"R2 Score=\", metrics.r2_score(y_test,y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygW1IzRf-gqD",
        "colab_type": "text"
      },
      "source": [
        "Among all the algorithms, the \"Random Forest\" outperformed with R2 score of \"0.93\", which is better among all, so the best fit model for machine learning is Random forest."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wt6UZ9GajDd1",
        "colab_type": "text"
      },
      "source": [
        "##**Downloading the output graphs we made**\n",
        "\n",
        "As we have saved some figures we can download the saved figures in one go from here.\n",
        "\n",
        "> Uncomment the code to download  all the figures.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUFfPwjCkRJW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Downloading the saved figure\n",
        "\n",
        "files.download('Detecting outliers-1.pdf')\n",
        "'''\n",
        "files.download('Detecting outliers-2.pdf')\n",
        "files.download('Detecting outliers-3.pdf')\n",
        "files.download('Detecting outliers-4.pdf')\n",
        "files.download('Detecting outliers-5.pdf')\n",
        "files.download('Detecting outliers-6.pdf')\n",
        "files.download('Detecting outliers-7.pdf')\n",
        "\n",
        "files.download('Heat Map.png')\n",
        "\n",
        "files.download('Most car sold.png')\n",
        "\n",
        "files.download('Price group.png')\n",
        "\n",
        "files.download('Random forest.png')\n",
        "files.download('Random forest-1.png')\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5FAHdD8jFcD",
        "colab_type": "text"
      },
      "source": [
        "##**Conclusion**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqCMDZ9RkVUQ",
        "colab_type": "text"
      },
      "source": [
        "I learnt various things during this project such as:\n",
        "\n",
        "*    Exploratory Data Analysis(EDA) can be carried out using Pandas plotting, and use of matplotlib and seaborn package to **develop better insights** about the data.\n",
        "*    Preprocessing helps in **dealing with missing values** and irregularities present in the data. \n",
        "*    Creating new features and **plotting various graphs** to anaysis the data from every viewpooint.\n",
        "*    Analysing **impact of various columns** like Mileage, Year and HP on the Price increase/decrease.\n",
        "*    The most important inference drawn from all this analysis is, we get to know what are the features on **which price is highly positively and negatively correlated with and which type of cars public preferred over time**.\n",
        "*    This analysis will helped me in **choosing which machine learning model** we can apply for various purpose.\n",
        "*   We tried various models of Machine Learning and from them we found the **best suitable model for ours was \"Random forest\"**, Errors were almost normallize in it thus result in most accurate result."
      ]
    }
  ]
}